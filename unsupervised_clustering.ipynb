{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "def mean_shift(centers, predict_data=None):\n",
    "    \"\"\"Function that perform mean shift clustering, can also predict values if predict_data is passed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    centers : 2D array like\n",
    "        centers of data to perform clustering on\n",
    "    predict_data : 2D array like, optional\n",
    "        data to be predicted by the clustering, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cluster_centers, labels, num_features, predict\n",
    "        cluster_centers: centers after clustering\n",
    "        labels: labels of each point\n",
    "        num_features: number of features seen during fit\n",
    "        predict: predicted values by the clustering for predict_data\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    Exception\n",
    "        raise exception when normal array (non 2D array) is passed in as predict data\n",
    "    \"\"\"\n",
    "    ms = MeanShift()\n",
    "    clustering = ms.fit(centers)\n",
    "    cluster_centers = clustering.cluster_centers_\n",
    "    labels = clustering.labels_\n",
    "    num_features = clustering.n_features_in_\n",
    "    if type(predict_data) == type(array) or type(np.array):\n",
    "        try: predicted = clustering.predict(predict_data)\n",
    "        except: raise Exception ('Use 2D array for predict_data')\n",
    "    else:\n",
    "        predicted = None\n",
    "    return cluster_centers, labels, num_features, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "def perform_DBSCAN(data, eps, min_samples):\n",
    "    \"\"\"Perform DBSCAN algorithm on a given set of data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 2D array-like\n",
    "        array of data of interest to perform DBSCAN\n",
    "    eps : float\n",
    "        The maximum distance between two samples for one to be considered as in the neighborhood of the other. \n",
    "        This is not a maximum bound on the distances of points within a cluster. \n",
    "        This is the most important DBSCAN parameter to choose appropriately for your data set and distance function.\n",
    "    min_samples : int\n",
    "        The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. \n",
    "        This includes the point itself.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels, num_features, core_sample_indices, components\n",
    "        labels: Cluster labels for each point in the dataset given to fit(). Noisy samples are given the label -1.\n",
    "        num_features: Number of features seen during fit.\n",
    "        core_sample_indices: Indices of core samples.\n",
    "        components: Copy of each core sample found by training.\n",
    "    \"\"\"\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(data)\n",
    "    labels = clustering.labels_\n",
    "    num_features = clustering.n_features_in_\n",
    "    core_sample_indices = clustering.core_sample_indices_\n",
    "    components = clustering.components_\n",
    "    return labels, num_features, core_sample_indices, components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "def hierarchical_clustering(data, n_clusters=2, linkage='ward', distance_threshold=None):\n",
    "    \"\"\"Function that performs hiearchical clustering and fit to an array of data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 2D array\n",
    "        data to be fitted\n",
    "    n_clusters : int, default=2\n",
    "        number of clusters to find\n",
    "    linkage : {'ward', 'complete', 'average', 'single'}, default='ward'\n",
    "        Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. \n",
    "        The algorithm will merge the pairs of cluster that minimize this criterion.\n",
    "        \n",
    "        'ward' minimizes the variance of the clusters being merged.\n",
    "        'average' uses the average of the distances of each observation of the two sets.\n",
    "        'complete' or 'maximum' linkage uses the maximum distances between all observations of the two sets.\n",
    "        'single' uses the minimum of the distances between all observations of the two sets.\n",
    "    distance_threshold : float, default=None\n",
    "        The linkage distance threshold above which, clusters will not be merged. \n",
    "        If not None, n_clusters must be None and compute_full_tree must be True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num_clusters : int\n",
    "        The number of clusters found by the algorithm\n",
    "    labels : ndarray of shape (n_samples)\n",
    "        Cluster labels for each point.\n",
    "    num_leaves : int\n",
    "        Number of leaves in the hierarchical tree\n",
    "    num_connected_components : int\n",
    "        The estimated number of connected components in the graph\n",
    "    num_features : int\n",
    "        number of features seen during fit\n",
    "    \"\"\"\n",
    "    model = AgglomerativeClustering(linkage=linkage, n_clusters=n_clusters, distance_threshold=distance_threshold)\n",
    "    model.fit(data)\n",
    "    num_clusters = model.n_clusters_\n",
    "    labels = model.labels_\n",
    "    num_leaves = model.n_leaves_\n",
    "    num_connected_components = model.n_connected_components_\n",
    "    num_features = model.n_features_in_\n",
    "    return num_clusters, labels, num_leaves, num_connected_components, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture \n",
    "def gaussian_mixture_model(data, num_components, num_random_state=0, predict_data=None):\n",
    "    \"\"\"Perform unsupervised learning with gaussian mixture model for a given data, and make prediction if needed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 2D array\n",
    "        Array of data to be fitted with Gaussian Mixture Model\n",
    "    num_components : int\n",
    "        number of underlying Gaussian distributions\n",
    "    num_random_state : int\n",
    "        random seed for initialization, by default 0\n",
    "    predict_data : 2D array, optional\n",
    "        array of data to be predicted from the model, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predicted\n",
    "        predicted is the predicted data of data passed into the model, which is predict_data\n",
    "    \"\"\"\n",
    "    GMM = GaussianMixture(n_components=num_components, random_state=num_random_state).fit(data)\n",
    "    if type(predict_data) == type(array) or type(np.array):\n",
    "        predicted = GMM.predict(predict_data)\n",
    "    else: predicted = None\n",
    "    return predicted"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
